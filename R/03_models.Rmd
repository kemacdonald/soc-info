---
title: "Soc-Info Statistical Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Setup

```{r libraries}
library(magrittr); library(tidyverse); library(here); 
library(rstanarm); library(brms)
source(here("R/soc_info_helpers.R"))
options(mc.cores=parallel::detectCores())
set.seed (3875)
```

Read data. 

```{r read data}
d_path <- "data/03_merged_data/"
d <- read_csv(here(d_path, "goal_actions_master.csv")) 
```

# Experiment 1 

```{r e1 data filter}
d_model_e1 <- d %>%
  filter(manip_check_score >= 2, str_detect(experiment, "e1")) %>% 
  distinct(id, condition, action_response, action_r_collap, action_trial_time, ig,
           entropy_change, prior, posterior, slider_value_normalized, hypothesis_type) %>% 
  mutate(condition_fact = factor(condition, 
                                 levels = c("nogoal", "learning", "presentation",
                                            "performance")),
         action_response_fact = factor(action_response, 
                                       levels = c("button", "handle", "both")),
         action_num = ifelse(action_r_collap == "both", 0, 1))
```

## E1: Logit model of action selections

```{r action logit model}
t_prior <- student_t(df = 7, location = 0, scale = 2.5)
m_act_logit <- stan_glm(action_num ~ condition_fact, 
                        data = d_model_e1,
                        family = binomial(link = "logit"),
                        prior = t_prior, prior_intercept = t_prior)

samples_logit_act_e1 <- m_act_logit %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id)
```

## E1: RT Model

```{r rt model e1}
d_rt_e1 <- d_model_e1 %>% 
  rename(rt = action_trial_time) %>% 
  filter(rt <= 120) %>% 
  mutate(log_rt = log(rt))

m_rt_e1 <- stan_lm(
  rt ~ condition_fact,
  data = d_rt_e1,
  prior = R2(0.75),
  adapt_delta = 0.99 # changed from 0.8 to 0.99 because of warning about divergent samples
)

# Extract posterior samples for RT differences.
samples_rt_e1 <- m_rt_e1 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = condition, value = param_est, -sample_id) 
```

## E1: entropy analysis

Model entropy change across conditions.

```{r explore entropy models, eval = F}
m_entropy_e1_act <- stan_lm(
  entropy_change ~ condition_fact,
  data = d_model_e1,
  prior = R2(0.75)
)

m_entropy_e1_cond <- stan_lm(
  entropy_change ~ condition_fact,
  data = d_model_e1,
  prior = R2(0.75)
)

m_entropy_e1_int <- stan_lm(
  entropy_change ~ condition_fact * action_r_collap,
  data = d_model_e1,
  prior = R2(0.75)
)

m_entropy_e1_add <- stan_lm(
  entropy_change ~ condition_fact + action_r_collap,
  data = d_model_e1,
  prior = R2(0.75)
)

loo_act <- rstanarm::loo(m_entropy_e1_act)
loo_cond <- rstanarm::loo(m_entropy_e1_cond)
loo_int <- rstanarm::loo(m_entropy_e1_int)
loo_add <- rstanarm::loo(m_entropy_e1_add)

compare_models(loo_add, loo_int)
```

Additive model wins by the LOO procedure. So we fit this model and extract posteior samples

```{r e1 entropy additive model}
m_entropy_e1_add <- stan_lm(
  entropy_change ~ condition_fact + action_r_collap,
  data = d_model_e1,
  prior = R2(0.75)
)

samples_entropy_e1_add <- m_entropy_e1_add %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation,
                single_action_beta = action_r_collapsingle) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) %>% 
  mutate(eff_type = ifelse(str_detect(effect, "int"), "interaction", "main effect")) 
```

## E1: information gain

```{r e1 info gain}
m_ig_e1_add <- stan_lm(
  ig ~ condition_fact + action_r_collap,
  data = d_model_e1,
  prior = R2(0.75),
  adapt_delta = 0.99
)

samples_ig_e1_add <- m_ig_e1_add %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation,
                single_action_beta = action_r_collapsingle) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) 
```

# Experiment 2

```{r e2 filter}
d_model_e2 <- d %>%
  filter(manip_check_score >= 2, str_detect(experiment, "e2")) %>% 
  distinct(id, condition, action_response, action_r_collap, action_trial_time, 
           entropy_change, ig, social_condition) %>% 
  mutate(condition_fact = factor(condition, 
                                 levels = c("nogoal", "performance", "presentation",
                                            "learning")),
         action_response_fact = factor(action_response, 
                                       levels = c("button", "handle", "both")),
         action_num = ifelse(action_r_collap == "both", 0, 1))
```

## E2 actions decisions

```{r action logit model e2 interaction}
t_prior <- student_t(df = 7, location = 0, scale = 2.5)

# remove the presentation condition because it does not have no-social context
m_act_logit_e2_int <- d_model_e2 %>% 
  stan_glm(
    formula = action_num ~ condition_fact * social_condition, 
    data = .,
    family = binomial(link = "logit"),
    prior = t_prior, prior_intercept = t_prior
    )

samples_logit_act_e2_int <- m_act_logit_e2_int %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                social_beta =  social_conditionsocial,
                int_learn_social = `condition_factlearning:social_conditionsocial`,
                int_perf_social = `condition_factperformance:social_conditionsocial`
                ) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) %>% 
  mutate(eff_type = ifelse(str_detect(effect, "int"), "interaction", "main effect")) 
```

Test main effects 

```{r action logit e2}
t_prior <- student_t(df = 7, location = 0, scale = 2.5)

# remove the presentation condition because it does not have no-social context
m_act_logit_e2 <- d_model_e2 %>% 
  stan_glm(action_num ~ condition_fact + social_condition, 
                        data = .,
                        family = binomial(link = "logit"),
                        prior = t_prior, prior_intercept = t_prior)

samples_logit_act_e2 <- m_act_logit_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation
                ) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) 
```

Compare the interaction and additive models.

```{r compare action models e2, eval = F}
loo_add_e2 <- rstanarm::loo(m_act_logit_e2)
loo_int_e2 <- rstanarm::loo(m_act_logit_e2_int)

compare_models(loo_add_e2, loo_int_e2)
```

The model with the interaction term is not doing much better.

## E2: RT on decision trials 

Modeled as a function of condition and social context.

```{r filter rt data e2}
d_rt_e2 <- d_model_e2 %>% 
  rename(rt = action_trial_time) %>% 
  filter(rt > 0, rt <= 120) %>% 
  mutate(log_rt = log(rt))
```

```{r rt model e2, eval = F}
# only use condition and keep rts in rt space
m_rt_e2 <- stan_lm(
  rt ~ condition_fact,
  data = d_rt_e2,
  prior = R2(0.75),
  adapt_delta = 0.99 # changed from 0.8 to 0.99 because of warning about divergent samples
)

# add social context as additive effect
m_rt_e2_add <- stan_lm(
  log_rt ~ condition_fact + social_condition,
  data = d_rt_e2,
  prior = R2(0.75)
  #adapt_delta = 0.99 # changed from 0.8 to 0.99 because of warning about divergent samples
)

# add interaction term for goal prompt and social context
m_rt_e2_int <- stan_lm(
  log_rt ~ condition_fact * social_condition,
  data = filter(d_rt_e2, condition != "presentation"),
  prior = R2(0.75)
  #adapt_delta = 0.99 # changed from 0.8 to 0.99 because of warning about divergent samples
)
```

Compare RT models.

```{r compare rt models e2, eval = F}
loo_rt_e2 <- rstanarm::loo(m_rt_e2)
loo_rt_add_e2 <- rstanarm::loo(m_rt_e2_add)
loo_rt_int_e2 <- rstanarm::loo(m_rt_e2_int)
compare_models(loo_rt_e2, loo_rt_add_e2)
```

The model using just goal condition to predict response times does best. So we extract the posterior samples from that model.

```{r extract rt samples e2}
m_rt_e2 <- stan_lm(
  rt ~ condition_fact,
  data = d_rt_e2,
  prior = R2(0.75),
  adapt_delta = 0.99 # changed from 0.8 to 0.99 because of warning about divergent samples
)

samples_rt_e2 <- m_rt_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = condition, value = param_est, -sample_id) 
```

## E2: entropy change across conditions

Here we include the additive effects of action resopnse and social condition. Including the interaciton term did not improve model fit and we did not have predictions for any two or three-way interactions.

```{r entropy model e2}
m_entropy_act_e2 <- stan_lm(
  entropy_change ~ condition_fact + action_r_collap + social_condition,
  data = d_model_e2,
  prior = R2(0.75)
)

samples_entropy_e2 <- m_entropy_act_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation,
                single_action_beta = action_r_collapsingle,
                social_beta = social_conditionsocial) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) 
```

## E2: ig across conditions

```{r ig model e2}
m_ig_act_e2 <- stan_lm(
  ig ~ condition_fact + action_r_collap + social_condition,
  data = d_model_e2,
  prior = R2(0.75)
)

samples_ig_e2 <- m_ig_act_e2 %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation,
                single_action_beta = action_r_collapsingle,
                social_beta = social_conditionsocial) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = effect, value = param_est, -sample_id) 
```

# Save posterior samples 

```{r save models and samples}
models <- list(action_model_e1 = m_act_logit,
               rt_model_e1 = m_rt_e1,
               ent_model_e1 = m_entropy_e1_add,
               ig_model_e1 = m_ig_e1_add,
               action_model_e2 = m_act_logit_e2,
               action_model_e2_int = m_act_logit_e2_int,
               rt_model_e1 = m_rt_e2,
               ent_model_e2 = m_entropy_act_e2,
               ig_model_e1 = m_ig_act_e2)

posteriors <- list(action_logit_samples_e1 = samples_logit_act_e1,
                   rt_samples_e1 = samples_rt_e1,
                   ent_samples_e1 = samples_entropy_e1_add,
                   ig_samples_e1 = samples_ig_e1_add,
                   action_logit_samples_e2 = samples_logit_act_e2,
                   action_logit_samples_e2_int = samples_logit_act_e2_int,
                   rt_samples_e2 = samples_rt_e2,
                   ent_samples_e2 = samples_entropy_e2,
                   ig_samples_e2 = samples_ig_e2)

saveRDS(posteriors, file = here("data/03_merged_data", "soc-info-posterior-samples.rds"))
saveRDS(models, file = here("data/03_merged_data", "soc-info-models.rds"))
```
