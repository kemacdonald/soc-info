---
title: "Soc-Info Statistical Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Setup

```{r}
library(magrittr); library(tidyverse); library(here); 
library(rstanarm); library(brms)
source(here("R/soc_info_helpers.R"))
options(mc.cores=parallel::detectCores())
```

Read data. 

```{r}
d_path <- "data/03_merged_data/"
d <- read_csv(here(d_path, "goal_actions_master.csv")) 
```

## Model condition difference in action selection

Since there were three options, I think we need to use a softmax or multinomial regression. No repeated measurements, so we don't model random effects. From [this](https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/) article:

> The multinomial logistic regression estimates a separate binary logistic regression model for each dummy variables.  The result is M-1 binary logistic regression models.  Each model conveys the effect of predictors on the probability of success in that category, in comparison to the reference category.

> Remember, multinomial logistic regression reports the odds of being in the different outcome categories in reference to some base group.

> Because of the indeterminacy in the regression coe cients, we can interpret the regression coe cients only relative to the reference category. In softmax regression, the regression coeficients can be conceived in terms of the log odds of each outcome relative to the reference outcome:

```{r}
d_model <- d %>%
  filter(manip_check_score >= 2) %>% 
  select(id, condition, action_response, action_trial_time) %>% 
  unique() %>% 
  mutate(condition_fact = factor(condition, 
                                 levels = c("nogoal", "presentation", "learning", 
                                            "performance")),
         action_response_fact = factor(action_response, 
                                       levels = c("button", "handle", "both")))
```

```{r}
set.seed (3875)

m <- brm(action_response_fact ~ condition_fact,
             data=d_model,
             family="categorical", 
             prior=c(set_prior ("normal (0, 8)")))
summary(m)
```

Extract and clean up the posterior samples.

```{r}
tidy_samples <- posterior_samples(m, "b") %>% 
  mutate(sample_id = seq(1, n())) %>% 
  gather(key = param_name, value = estimate, -sample_id) %>% 
  mutate(param_name = str_replace(param_name, "b_mu", ""),
         param_name = str_replace(param_name, "condition_fact", ""),
         estimate_prob = logit_to_prob(estimate)) %>% 
  separate(param_name, into = c("model", "param_name")) 
```

Plot posterior distributions over model params. 

```{r}
tidy_samples %>% 
  filter(model == "both") %>% 
  ggplot(aes(x = estimate)) + 
  geom_line(stat = "density", size = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  #lims(x = c(-7, 7)) +
  facet_grid(param_name~model, scales = "free_x") +
  labs(title = "Posterior distribution over logit model predicting the 'both' action",
       subtitle = "Reference group is the 'no-goal' condition and 'button' action",
       x = "estimate (logit scale)")
```

## RT Model

```{r}
d_rt <- d_model %>% 
  rename(rt = action_trial_time) %>% 
  filter(rt <= mean(rt) + 3*sd(rt) & rt >= mean(rt) - 3*sd(rt)) %>% 
  mutate(log_rt = log(rt))


m_rt <- stan_lm(
  log_rt ~ condition_fact,
  data = d_rt,
  prior = R2(0.75)
)
```

Extract posterior samples for RT differences.

```{r}
samples_rt <- m_rt %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  dplyr::rename(no_goal = `(Intercept)`,
                learning_beta = condition_factlearning,
                performance_beta = condition_factperformance,
                presentation_beta = condition_factpresentation) %>% 
  select(-sigma, -R2, -`log-fit_ratio`) %>% 
  mutate(sample_id = 1:n()) %>% 
  gather(key = condition, value = param_est, -sample_id) %>% 
  mutate(rt_ms_scale = exp(param_est))
```

Plot posterior distributions over model params. 

```{r}
samples_rt %>% 
  filter(condition != "no_goal") %>% 
  ggplot(aes(x = param_est, color = condition)) + 
  ggthemes::scale_color_ptol() +
  geom_line(stat = "density", size = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(title = "Posterior distribution over linear model predicting RT on action trial",
       subtitle = "Reference group is the 'no-goal' condition",
       x = "rt estimate (log scale)")
```

## Entropy analysis

Compute prior and posterior entropy for each participant, and the entropy change.

```{r}
d_entropy <- d %>% 
  filter(manip_check_score >= 2) %>% 
  group_by(id, condition, hypothesis_type, action_response) %>% 
  summarise(entropy_est = compute_entropy(slider_value_normalized)) %>% 
  spread(hypothesis_type, entropy_est) %>% 
  mutate(entropy_change = prior - posterior,
         action_r_collap = ifelse(action_response == "both", "both", "single"))
```

Plot entropy change as a function of condition.

```{r}
d_entropy %>% 
  mutate(action_r_collap = ifelse(action_response == "both", "both", "single")) %>% 
  ggplot(aes(x = condition, y = entropy_change, color = condition)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_violin(draw_quantiles = 0.5, trim = T, width = 1, size = 1, 
              adjust = 1, fill = NA) +
  geom_jitter(width = 0.07, alpha = 1, shape = 21, color = "darkgrey") +
  ggthemes::scale_color_ptol() +
  labs(x = NULL, y = "entropy change") +
  facet_wrap(~action_r_collap)
```

Model entropy change across conditions.

```{r}

```




