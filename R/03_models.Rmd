---
title: "Soc-Info Statistical Models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Setup

```{r}
logit_to_prob <- function(x) {
  odds <- exp(x)
  prob <- odds / (1 + odds)
  prob
}
```

```{r}
library(magrittr); library(tidyverse); library(here); library(rstanarm) 
library(brms)
theme_set(theme_minimal() + theme(panel.border = element_rect(fill=NA, size=0.5, color = "grey"))) 
```

```{r}
options(mc.cores=parallel::detectCores ()) # Run on multiple cores
```
Read data. 

```{r}
d_path <- "data/02_tidy_data/"
d_file_name <- "goal_actions_ver3_tidy_pilot.csv"
d <- read_csv(here(d_path, d_file_name)) 
```

## Model condition difference in action selection

Since there were three options, I think we need to use a softmax or multinomial regression. No repeated measurements, so we don't model random effects. From [this](https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/) article:

> The multinomial logistic regression estimates a separate binary logistic regression model for each dummy variables.  The result is M-1 binary logistic regression models.  Each model conveys the effect of predictors on the probability of success in that category, in comparison to the reference category.

> Remember, multinomial logistic regression reports the odds of being in the different outcome categories in reference to some base group.

> Because of the indeterminacy in the regression coe cients, we can interpret the regression coe cients only relative to the reference category. In softmax regression, the regression coeficients can be conceived in terms of the log odds of each outcome relative to the reference outcome:

```{r}
d_model <- d %>%
  filter(manip_check_score == 3) %>% 
  select(id, condition, action_response) %>% 
  unique() %>% 
  mutate(condition_fact = factor(condition, 
                                 levels = c("nogoal", "presentation", "learning", 
                                            "performance")),
         action_response_fact = factor(action_response, 
                                       levels = c("button", "handle", "both")))
```

```{r}
set.seed (3875)

m <- brm(action_response_fact ~ condition_fact,
             data=d_model,
             family="categorical", 
             prior=c(set_prior ("normal (0, 8)")))
summary(m)
```

Extract and clean up the posterior samples.

```{r}
tidy_samples <- posterior_samples(m, "b") %>% 
  mutate(sample_id = seq(1, n())) %>% 
  gather(key = param_name, value = estimate, -sample_id) %>% 
  mutate(param_name = str_replace(param_name, "b_mu", ""),
         param_name = str_replace(param_name, "condition_fact", ""),
         estimate_prob = logit_to_prob(estimate)) %>% 
  separate(param_name, into = c("model", "param_name")) 
```

Plot posterior distributions over model params. 

```{r}
tidy_samples %>% 
  filter(model == "both") %>% 
  ggplot(aes(x = estimate)) + 
  geom_line(stat = "density", size = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  #lims(x = c(-7, 7)) +
  facet_grid(param_name~model, scales = "free_x") +
  labs(title = "Posterior distribution over logit model predicting the 'both' action",
       subtitle = "Reference group is the 'no-goal' condition and 'button' action",
       x = "estimate (logit scale)")
```
