---
title: "Should I learn or should I make it go? \\ Balancing informational and social goals in active learning"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Erica J. Yoon*}, {\large \bf Kyle MacDonald*}, {\large \bf Mika Asaba}, {\large \bf Hyowon Gweon}, \and {\large \bf Michael C. Frank} \\ \{ejyoon, kylem4, masaba, hyo, mcfrank\} @stanford.edu \\ Department of Psychology, Stanford University \\ *These authors contributed equally to this work.}

abstract: 
    "Our actions shape what we learn. Recent work suggests that people engage in efficient self-directed learning to maximize information gain. However, human learning often unfolds in social contexts where learners not only face informational goals (e.g. learn how something works) but also social goals (e.g. appear competent and impress others). How do these factors shape learners' decisions? Here, we present a computational model that integrates the value of social and information goals to predict the decisions that people will make in a simple active causal learning task. We show that an emphasis on performance or self-presentation goals leads to reduced chances of learning (E1). Next, we show that social context can push learners to pursue performance-oriented actions even when the learning goal is highlighted (E2). Our formal model of social-active learning successfully captures the empirical results. These findings are the first steps towards understanding the role of social reasoning in active learning contexts."
    
keywords:
    "active learning; social reasoning; information gain; OED; self-presentation; goal tradeoffs"
    
output: cogsci2016::cogsci_paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/', echo=F,
                      warning=F, cache=T, message=F, sanitize = T)

image_path <- "writing/cogsci2018/figs/"

library(png); library(grid)
library(gridExtra); library(xtable)
library(tidyverse); library(here);
library(jsonlite); library(binom)

source(here("R/soc_info_helpers.R"))
```

```{r read data and posterior samples}
d <- read_csv(here("data/03_merged_data/goal_actions_master.csv"))
d_prior <- read_csv(here("data/02_tidy_data/goal_actions_prior_tidy.csv"))
d_models <- readRDS(here("data/03_merged_data/soc-info-posterior-samples.rds"))
d_model_spec <- readRDS(here("data/03_merged_data/soc-info-models.rds"))
```

# Introduction

Imagine you are a novice cook and you have to decide what meal to prepare for a first date. 
Should you choose an easy favorite or should you attempt to make something new? 
While the familiar recipe can ensure a good meal, 
you may miss out on a new, delicious dish. 
The new recipe might taste even better, but it has a higher chance of failure. 

We often have to choose between *exploration* and *exploitation*: 
that is, actions that could (a) lead to an overt, readily accessible reward based on what we already know (*exploitation*) or (b) result in the discovery of new information [*exploration*; @sutton1998]. 
This decision of whether to explore or exploit is directly related to the relative strength of the goals within a particular context. 
In the cooking example, I can prioritize the goal of learning by cooking the new recipe, 
or I can instead focus on the performance goal by preparing the tried and true meal. 
Here, we explore the idea of this learning-performance goal tradeoff in a simple *active learning* context, 
where social factors may affect the goals we consider.

Active learning occurs when people are given control over the sequence of information in a learning context (e.g. try pressing different buttons on a toy, one by one, to see if it produces an effect). The key assumption is that learners will maximize the usefulness of their actions by gathering information that is especially helpful for their own learning. 
Active contexts lead to faster learning than passive contexts where people don't have control over the information flow, as suggested by empirical work in education [@grabinger1995rich], machine learning [@settles2012active], and cognitive psychology [@castro2009human]. 

But real-world learning usually takes place in rich social contexts 
with teachers, peer learners, or other people who can directly influence our learning. 
Indeed, it has been suggested that children and adults modulate their inferences depending on whether they generate their own evidence, or learn from evidence generated by others [e.g. @xu2007].
Other work suggests that children learn faster when observing intentional (more informative) actions compared to accidental (less informative) actions [@carpenter1998fourteen]. 
Moreover, adults and children will make even stronger inferences if they believe that another person selected their actions with the goal of helping them learn [i.e. teaching; @shafto2012learning]. 

However, social influences are not only present when we learn from others.
Even when we learn from our own actions, our social environment may affect our self-directed learning process. 
While previous models have captured how we optimize learning, either from our own actions or from others, they have been agnostic to other social factors that are ubiquitous in a learner's environment. 
People must integrate the value of social goals (e.g. looking competent or knowledgeable) and information goals when deciding what to do next. Moreover, actions that maximize learning are inherently risky in that you can potentially fail to produce an immediate outcome, and thus may be more difficult to undertake in with someone else present who might judge you as incompetent. 

How can active learning models be modified to accommodate this richer set of utilities? As a step towards answering this question, we model a learner who considers a mixture of learning and performance goals. 
A key assumption underlying inferences in recent Bayesian models of human social cognition is that 
people expect others to act approximately optimally given a utility function [e.g. @goodman2016; @jara2016]. 
Our model adopts the same utility-theoretic approach, and assumes an approximately optimal agent 
who reasons about the utility function that represents a weighted combination of multiple goals [@yoon2017]. 
Our model thus reflects a tradeoff between
different goals that a learner has in a social learning context.

We instantiate our model in a simple causal learning task and 
examine whether people choose actions that support learning vs. social goals. 
We present a toy with an uncertain causal mechanism (Figure \ref{fig:toy}), 
for which doing only one of the two possible actions (handle pull or button press) is disambiguating but potentially risks no immediate effect (i.e. neither sound nor light turning on), 
while doing both actions simultaneously is immediately rewarding for sure but is not informative for learning the toy's causal mechanism. 
Thus, the learner can choose between the two actions
that will each lead to one outcome (new discovery) or the other (immediate reward).
The learner's action rests on relative utilities he assigns to exploration versus exploitation, 
which in turn are determined in part by the presence or absence of another person he cares about (i.e. his boss).\footnote{From here on, we use a male pronoun for Bob, the learner, and female pronoun for Ann, the boss and observer.} 

In two experiments, we show that emphasizing performance or self-presentation goals leads to actions that are not informative and thus reduce the chances of learning (E1). Next, we show that the presence of an observer (i.e., a boss) pushes learners to pursue performance/presentation actions even when the learning goal is highlighted (E2). Finally, we present a Bayesian Data Analysis showing that the empirical results are consistent with predictions of our cognitive model of social-active learning.

# Computational model

```{r toy, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=2, fig.height=1.5, num.cols.cap=1, out.width='65%', fig.cap = "An example of the toy used in our paradigm."}
img <- png::readPNG("figs/toywlabel.png")
grid::grid.raster(img)
```

```{r model_diagram, include = T, fig.env = "figure*", fig.pos = "tb", fig.width=5, fig.asp = 0.7, out.width= "95%", fig.align='center', fig.cap = "Diagram of the computational model. The learner considers possible hypotheses: Toy 1 (handle pull turns on the light, button press turns on music, both actions cause both effects); Toy 2 (handle pull turns on music, button press turns on the light, both actions cause both effects); and Toy 3 (both actions cause both effects, but each action on its own does not produce any effect). The learner also considers his contextual goals. When an observer is absent, he considers his learning goal (to maximize information gain) and performance goal (e.g. to play music) and decides on an action. The learning goal favors a single action (e.g. pull the handle only) that can fully disambiguate, whereas the performance goal favors the both action (pull the handle AND push the button) that guarantees the most salient reward. When an observer is present, his decision for an action is based on his learning goal vs. presentational goal (to have the observer infer his competence or knowledge of how the toy works)."}
img1 <- rasterGrob(as.raster(readPNG(here(image_path, "model-obsAbs.png"))), 
                    interpolate = FALSE)

img2 <- rasterGrob(as.raster(readPNG(here(image_path, "model-obsPres.png"))), 
                   interpolate = FALSE)

grid.arrange(img1, img2, ncol = 2)
```

We model a learner's action choice based on 
his desire to learn how a toy works (*learning utility*), 
to make the toy operate and perform a given function (*performance utility*), 
or to present himself as a competent individual who knows how to make the toy work (*presentational utility*; see the model diagram in Figure \ref{fig:model_diagram}).

### Learning utility

The *learning utility* symbolizes the goal to learn new information, which in our paradigm is associated with figuring out how a given toy works. The learning utility is formally represented by an OED model ["Optimal Experiment Design"; @nelson2005; @lindley1956], which quantifies the *expected utility* of different information seeking actions. Here we follow the mathematical details of the OED approach as outlined in @coenen2017. The learner considers the hypothesis space $H$, and wants to determine the correct hypothesis. Based on a set of queries, each realized through taking an action, the learner thinks about the utility of the answer to each query. 
The utility of answer is equal to the *information gain*, which is the change in the learner's overall uncertainty (difference in entropy) before and after receiving an answer. This information gain is then the usefulness of the answer to the query, and thus is equal to the learning utility ($U_{learn}$):
$$ U_{learn} = U(a) = \frac{ent(H) - ent(H|a)}{log_2n}$$
\noindent
where $ent(H)$ is the Shannon entropy of $H$, which provides a measure of the overall amount of uncertainty in the learner's beliefs about the candidate hypothesis[@mackay2003].
Once the learner chooses a query $Q$, which yields an answer $a$, 
then he updates his beliefs about each hypothesis via standard Bayesian updating. 
Finally, the difference in entropy is normalized by $log_2 n$, where $n$ is the number of possible actions, to generate a value between 0 and 1.

### Performance utility

The *performance utility* is the utility of successfully making the toy operate and achieving an immediate rewarding outcome. 
Within our paradigm, the learner gains utility by seeing an immediate effect of music or light turning on. The expected performance utility ($U_{perf}$) before the learner chooses an action is then the likelihood of an effect $m$ given the learner's action $a$. Thus, the performance utility is maximized when the toy is expected to "go."
$$ U_{perf} = P_L(m | a) $$
\noindent


When there is no observer present ($obs = no$), the learner considers the tradeoff between the learning utility and performance utility, and he determines his action based on a weighted combination of the two utilities: 
$$ U(\phi; obs = no) = \phi_{learn} \cdot U_{learn} + \phi_{perf} \cdot U_{perf} ,$$
\noindent
where $\phi$ is a mixture parameter governing the extent to which the learner prioritizes learning over performance. 

### Presentation utility

When there is another person present to observe the learner's action, this observer $O$ is expected to reason about the competence $c$ of the learner $L$ which is equal to whether the learner was able to make the toy produce an effect.
The learner thinks the observer's inferential process, and the expected *presentational* utility ($U_{pres}$) is based on maximizing the apparent competence inferred by the observer.
$$ P_O(c) \propto P_L(m | a)$$
$$ U_{pres} = P_O(c)$$
When there is an observer present ($obs = yes$), the learner considers the tradeoff between all three utilities: the learning utility, performance utility and presentational utility: 
$$ U(\phi; obs = yes) = \phi_{learn} \cdot U_{learn} + \\ \phi_{perf} \cdot U_{perf} + \phi_{pres} \cdot U_{pres}$$
The learner $L$ chooses his action $a$ approximately optimally (as per optimality $\lambda$) based on the expected utility given his goal weights and observer presence.
$$ P_L(a | \phi, obs) \propto \exp(\lambda \cdot \mathbb{E}[U(\phi; obs)])$$

# Experiment 1

```{r e1 filter}
d_e1 <- d %>% filter(str_detect(experiment, "e1"))
```

In Experiment 1 (E1), we first wanted to confirm that participants would choose different actions depending on what goal was highlighted. We were also interested in how people would act when no goal was specified. Importantly, participants were limited to selecting a *single* action, which meant the opportunity cost was at its highest. Participants were asked to imagine that they needed to act on a toy with an uncertain causal mechanism, and were assigned to different goal conditions: (1) Learning (learn how the toy works), (2) Performance (make the toy play music), (3) Presentation (impress their boss), and (4) No goal. We hypothesized that participants would choose an informative action more often in the following order of goal conditions (decreasing): Learning, No goal, Performance, and Presentation.\footnote{Our hypothesis, method, model and data analysis were pre-registered prior to data collection on the Open Science Framework (https://osf.io/kcjau). All experiments, data, model scripts, and analysis codes for the statistical models can be found in the online repository for this project: https://github.com/kemacdonald/soc-info.}

```{r e1_behav_results_plot, include = T, fig.env = "figure*", fig.pos = "tb", fig.width=5, fig.asp = 0.7, out.width= "95%", fig.align='center', fig.cap = "Behavioral results for E1. A: Proportion of action decisions for each goal condition. Error bars represent 95\\% binomial confidence intervals computed using a Bayesian beta-binomial model. B: Participants' response times on the action decisions. Each point represents a participant with the width of the violin representing the density of the data at that value. C: Participants' belief change (entropy; information gain in bits) as a function of condition. Lower values represent higher certainty after selecting an action."}
png::readPNG(here::here(image_path, "e1_plot.png")) %>% 
  grid::grid.raster()
```

## Method

### Participants

```{r e1 participants}
e1_participants <- d_e1 %>% 
  distinct(id, condition) %>% 
  count(condition)

n_run <- sum(e1_participants$n)

e1_excluded <- d_e1 %>%
  filter(manip_check_score >= 2) %>% 
  distinct(id, condition) %>% 
  count(condition)

n_excluded <- n_run - sum(e1_excluded$n)
n_analyzed <- sum(e1_excluded$n)
```

We recruited `r n_run` participants (45-51 per condition) on Amazon’s Mechanical Turk, with IP addresses in the United States and a task approval rate above 85%. We excluded `r n_excluded` participants who failed to answer at least two out of three manipulation check questions correctly (see Procedure section for details on the manipulation check), and thus the remaining `r n_analyzed` participants were included in our final analysis.

### Stimuli and Design

We presented images of three different toys that look very similar but each work in different ways, and provided instructions for them (see captions for Figure \ref{fig:model_diagram}).
Based on the instructions, doing both button press and handle pull was immediately rewarding but uninformative (as it does not disambiguate the causal mechanism in any way), whereas either of the single actions was completely disambiguating, but was uncertain to produce an immediate outcome. Each toy had a label at the front, indicating which action(s) will make the toy operate, and with which outcome effect.

We asked participants to act on one of these toys; importantly, the given toy was missing its label, and thus it was uncertain whether the toy was Toy 1, 2 or 3. We randomly assigned participants into four goal conditions. In *No-goal* condition, participants were asked to select an action without any goal specified. In *Learning*, *Performance*, and *Presentation* conditions, we asked participants to imagine that they were children's toy developers and one day their boss approached them. We then instructed participants to: figure out the correct label for the toy (*Learning*); make the toy play music (or turn the light on; *Performance*); or impress their boss and show that they are competent (*Presentation*). We asked participants to select an action to accomplish the specified goal (if any), out of: "press the button", "pull the handle", or "press the button and pull the handle" (presented in random order).

### Procedure

In the initial *exposure phase*, we showed participants an example toy, and then gave instructions for each of the three toy types. We presented Toy 1 and Toy 2 instructions in a randomized order first, and then Toy 3 instructions. Afterwards, they were asked what they would do to make each toy operate as manipulation check (e.g. "How would you make [this] toy play music?"). 

In the *test phase*, participants read a scenario for one of the three goal conditions, followed by the question: "If you only had one chance to try a SINGLE action to [pursue the specified goal], which action would you want to take? You will get a 10 cent bonus ... if you [achieve the given goal]". Participants made their *action decisions* accordingly. 
Before and after they chose an action and saw its effect on the toy, 
we asked participants to rate the likelihood that an unknown toy is Toy 1, 2, or 3,
which indicated their *belief change* between before and after their decisions.

## Results and discussion

### Analysis plan

We present behavioral analyses of participants' (1) action decisions, (2) action decision times, and (3) belief change (i.e., learning). Decision times correspond to the latency to make an action selection as measured from the start of the action decision trial (all RTs were analyzed in log space). We quantified participants' beliefs about the possible toy designs using entropy, and belief change was measured as the difference in entropy before and after selecting an action.

We used the `rstanarm` [@gabry2016rstanarm] package to fit Bayesian regression models estimating the differences across conditions. We report the uncertainty in our point estimates using 95% Highest Density Intervals (HDI). The HDI provides a range of credible values given the data and model. 

### Action decisions:

```{r actions summarize model contrasts}
e1_contrasts_act <- d_models$action_logit_samples_e1 %>% 
  group_by(effect) %>% 
  summarise(prop = mean(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

```{r actions get condition betas}
# no-goal is the intercept or reference group
ms_act_e1 <- d_models$action_logit_samples_e1 %>% 
  spread(effect, param_est) %>% 
  mutate(performance = no_goal + performance_beta,
         learning = no_goal + learning_beta,
         presentation = no_goal + presentation_beta) %>% 
  select(sample_id, no_goal, performance, learning, presentation) %>% 
  gather(key = condition, value = param_est, -sample_id) %>% 
  mutate(act_prob_scale = logit_to_prob(param_est)) %>% 
  group_by(condition) %>% 
  summarise(prop = mean(act_prob_scale),
            hdi_lower = quantile(act_prob_scale, probs = 0.025),
            hdi_upper = quantile(act_prob_scale, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

We modeled action decisions using a logistic regression specified as \texttt{$action \sim goal\_condition$} with the No-goal condition as the reference category. Participants' tendency to select a "single" action varied across conditions as predicted (see Figure \ref{fig:e1_behav_results_plot}A), with the highest proportion occuring in the Learning context, followed by the No-goal context, then Performance, and the fewest single actions in the Presentation condition. 

Compared to the No-goal condition, participants selected the single action at a greater rate in the Learning condition ($\beta$ = `r e1_contrasts_act$prop[1]`, [`r e1_contrasts_act$hdi_lower[1]`, `r e1_contrasts_act$hdi_upper[1]`]) and at lower rate in the Presentation context ($\beta$ = `r e1_contrasts_act$prop[4]`, [`r e1_contrasts_act$hdi_lower[4]`, `r e1_contrasts_act$hdi_upper[4]`]), with the null value of zero difference condition falling well outside the 95% HDI, and at similar rate in the Performance condition ($\beta$ = `r e1_contrasts_act$prop[3]`, [`r e1_contrasts_act$hdi_lower[3]`, `r e1_contrasts_act$hdi_upper[3]`]) with the 95% HDI including the null.

### Action decision times:

```{r rt contrasts e1}
e1_contrasts_rt <- d_models$rt_samples_e1 %>% 
  group_by(condition) %>% 
  summarise(rt = median(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 1) 
```

```{r rt group means e1}
ms_rt_e1 <- d_models$rt_samples_e1 %>% 
  spread(condition, param_est) %>% 
  mutate(performance = no_goal + performance_beta,
         learning = no_goal + learning_beta,
         presentation = no_goal + presentation_beta) %>% 
  select(sample_id, no_goal, performance, learning, presentation) %>% 
  gather(key = condition, value = rt_sec_scale, -sample_id) %>% 
  group_by(condition) %>% 
  summarise(rt = median(rt_sec_scale),
            hdi_lower = quantile(rt_sec_scale, probs = 0.025),
            hdi_upper = quantile(rt_sec_scale, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 1) 
```

We analyzed response times in log space using the same model specification. Figure \ref{fig:e1_behav_results_plot}A shows the full RT data distribution. Compared to the No-goal condition, participants took on on average `r e1_contrasts_rt$rt[1]` seconds longer to generate a decision in the Learning condition, but produced similar response times in the Performance and Presentation conditions.

### Belief change:

```{r entropy contrasts e1}
e1_contrasts_ent <- d_models$ent_samples_e1 %>% 
  group_by(effect) %>% 
  summarise(ent_change = median(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

```{r entropy group means e1}
e1_ent_means <- d_models$ent_samples_e1 %>% 
  select(-eff_type) %>% 
  spread(effect, param_est) %>% 
  mutate(performance_both = no_goal + performance_beta,
         learning_both = no_goal + learning_beta,
         presentation_both = no_goal + presentation_beta,
         no_goal_single = no_goal + single_action_beta,
         performance_single = no_goal + performance_beta + single_action_beta,
         learning_single = no_goal + learning_beta + single_action_beta,
         presentation_single = no_goal + presentation_beta + single_action_beta) %>% 
  rename(no_goal_both = no_goal) %>% 
  select(-contains("beta")) %>% 
  gather(key = condition, value = param_est, -sample_id) %>% 
  group_by(condition) %>% 
  summarise(ent_change = mean(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

We modeled change in entropy as a function of goal condition and participants' action choices: \texttt{$entropy\_change \sim goal\_condition + action\_response$} (see Figure \ref{fig:e1_behav_results_plot}C) . Across all conditions, people who selected the single action showed a greater reduction in entropy ($\beta$ = `r e1_contrasts_ent$ent_change[5]`, [`r e1_contrasts_ent$hdi_lower[5]`, `r e1_contrasts_ent$hdi_upper[5]`], i.e., learned more from their action. We did not see evidence of an interaction between goal condition and action selection. However, recall that a larger proportion of participants selected the single action in the Learning context, so the probability of learning is higher in this scenario.

```{r e2_results, include = T, fig.env = "figure*", fig.pos = "tb", fig.width=5, fig.asp = 0.4, out.width= "95%", fig.align='center', fig.cap = "Behavioral and model fitting results for E2. A: Action decisions with color representing social context, from human data (top) and fitted model predictions (bottom). B: Decision times. C: Belief change. D: Inferred phi values for each goal-context condition. All other plotting conventions are the same as Figure 3."}
png::readPNG(here::here(image_path, "e2_plot_wBDA.png")) %>%
  grid::grid.raster()
```

# Experiment 2

```{r e2 filter}
d_e2 <- d %>% filter(str_detect(experiment, "e2"))
```

In E1, we confirmed that participants made different action choices depending on the goal conditions, as we previously predicted. 
In E2, our goals were three-fold: 
(1) to replicate the results in E1 to see whether people choose the same action choices given the same goal conditions; 
(2) to manipulate goals *and* social contexts, fully crossing the different goal conditions with the presence/absence of the boss, to see whether the social context affects people's decision differently in each goal condition; and 
(3) to compare the empirical data with the predictions of the model.
We hypothesized that participants in the No-social learning/no-goal condition will select the single action option at a greater rate compared to the Social learning/no-goal condition, but they should select the both action option at the same, high rate in the Social and No-social performance condition.

## Method

### Participants

```{r e2 participants}
e2_participants <- d_e2 %>% 
  distinct(id, condition, social_condition) %>% 
  count(condition, social_condition)

n_run_e2 <- sum(e2_participants$n)

e2_excluded <- d_e2 %>%
  filter(manip_check_score >= 2) %>% 
  distinct(id, condition, social_condition) %>% 
  count(condition, social_condition)

n_excluded_e2 <- n_run_e2 - sum(e2_excluded$n)
n_analyzed_e2 <- sum(e2_excluded$n)
```

With the same recruitment and exclusion criteria as E1, we recruited `r n_run_e2` participants (42-51 per condition), and `r n_analyzed_e2` participants were included in our final analysis.

### Stimuli and Design

The stimuli and design were identical to E1, except we had seven different goal $\times$ social conditions. Goals remained identical to ones presented in E1; social conditions varied depending on whether the boss was present in the story (*Social*) or she was absent (*No-social*). Thus, the conditions from E1 were used as *Social-learning*, *Social-performance*, *Social-presentation*, and *No-social-no-goal* conditions in E2. We added three more conditions: *No-social-learning*, *No-social-performance*, and *Social-no-goal*. Note that we did not have *No-social-presentation* condition, because presentation goal by definition was to present oneself as competent to and impress another person.  

### Procedure

The procedure was identical to E1.

## Results and discussion

### Action decisions:

```{r e2 actions summarize model contrasts}
e2_contrasts_act_soc <- d_models$action_logit_samples_e2 %>% 
  group_by(effect) %>% 
  summarise(prop = mean(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 3) 


e2_contrasts_act <- d_models$action_logit_samples_e2_int %>% 
  group_by(effect, eff_type) %>% 
  summarise(prop = mean(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 3) 
```

```{r e2 actions get condition betas}
# no-goal-no-social is the intercept or reference group
ms_act_e2 <- d_models$action_logit_samples_e2 %>% 
  spread(effect, param_est) %>% 
  rename(social_beta = social_conditionsocial) %>% 
  mutate(no_goal_soc = no_goal + social_beta,
         performance_no_soc = no_goal + performance_beta,
         performance_soc = no_goal + performance_beta + social_beta,
         learning_no_soc = no_goal + learning_beta,
         learning_soc = no_goal + learning_beta + social_beta,
         presentation_soc = no_goal + presentation_beta + social_beta) %>% 
  select(- ends_with("_beta")) %>% 
  gather(key = condition, value = param_est, -sample_id) %>% 
  mutate(act_prob_scale = logit_to_prob(param_est)) %>% 
  group_by(condition) %>% 
  summarise(prop = mean(act_prob_scale),
            hdi_lower = quantile(act_prob_scale, probs = 0.025),
            hdi_upper = quantile(act_prob_scale, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

We modeled action decisions using a logistic regression (\texttt{$action \sim goal\_condition * social\_context$}) with the No-social no-goal condition as the reference category. We replicated the key finding from E1: participants selected a "single" action more often in Learning condition, followed by No goal, Performance, and Presentation. 

There was a main effect of social context, with participants being less likely to select the single action when their boss was present ($\beta =$ `r e2_contrasts_act_soc$prop[5]`, [`r e2_contrasts_act_soc$hdi_lower[5]`, `r e2_contrasts_act_soc$hdi_upper[5]`]). Finally, there was evidence for a reliable interaction between goal condition and social context such that the effect of social context was present in the Learning and No-goal conditions, but not in the Performance condition ($\beta$ $_{int}$ = `r e2_contrasts_act$prop[4]`, [`r e2_contrasts_act$hdi_lower[4]`, `r e2_contrasts_act$hdi_upper[4]`]).

### Action decision times:

```{r rt contrasts e2}
e2_contrasts_rt <- d_models$rt_samples_e2 %>% 
  group_by(condition) %>% 
  summarise(rt = median(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

```{r rt group means e2}
ms_rt_e2 <- d_models$rt_samples_e2 %>% 
  spread(condition, param_est) %>% 
  mutate(performance = no_goal + performance_beta,
         learning = no_goal + learning_beta,
         presentation = no_goal + presentation_beta) %>% 
  select(sample_id, no_goal, performance, learning, presentation) %>% 
  gather(key = condition, value = rt_sec_scale, -sample_id) %>% 
  group_by(condition) %>% 
  summarise(rt = mean(rt_sec_scale),
            hdi_lower = quantile(rt_sec_scale, probs = 0.025),
            hdi_upper = quantile(rt_sec_scale, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 3) 
```

We replicated the key decision time finding from E1: slower decision times in the Learning context. On average, participants took `r ms_rt_e2$m[2]` seconds to generate a response in the No-goal condidition and `r ms_rt_e2$m[1]` seconds in the Learning condition. In contrast, decisions were faster in the Performance ($\beta$ = `r e2_contrasts_rt$rt[3]` sec, [`r e2_contrasts_rt$hdi_lower[3]`, `r e2_contrasts_rt$hdi_upper[3]`]) and Presentation (`r e2_contrasts_rt$rt[4]` seconds, [`r e2_contrasts_rt$hdi_lower[4]`, `r e2_contrasts_rt$hdi_upper[4]`]) conditions, which were similar to one another (see Fig \ref{fig:e2_results}B). There was no evidence of a main effect of social context or an interaction between goal condition and social context. Note that we did not see a difference in decision times between the Learning and No-Goal conditions, which is different from the pattern in E1.

### Belief change:

```{r entropy contrasts e2}
e2_contrasts_ent <- d_models$ent_samples_e2 %>% 
  group_by(effect) %>% 
  summarise(ent_change = mean(param_est),
            hdi_lower = hdi_lower(param_est),
            hdi_upper = hdi_upper(param_est)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

```{r entropy group means e2}
e2_ent_means <- d_models$ent_samples_e2 %>% 
  spread(effect, param_est) %>% 
  mutate(performance_both = no_goal + performance_beta,
         learning_both = no_goal + learning_beta,
         presentation_both = no_goal + presentation_beta,
         no_goal_single = no_goal + single_action_beta,
         performance_single = no_goal + performance_beta + single_action_beta,
         learning_single = no_goal + learning_beta + single_action_beta,
         presentation_single = no_goal + presentation_beta + single_action_beta) %>% 
  rename(no_goal_both = no_goal) %>% 
  select(-contains("beta")) %>% 
  gather(key = condition, value = param_est, -sample_id) %>% 
  group_by(condition) %>% 
  summarise(ent_change = mean(param_est),
            hdi_lower = quantile(param_est, probs = 0.025),
            hdi_upper = quantile(param_est, probs = 0.975)) %>% 
  mutate_if(.predicate = is.numeric, .funs = round, digits = 2) 
```

Across all conditions, participants who selected the single action showed a greater reduction in entropy ($\beta$ = `r e2_contrasts_ent$ent_change[5]`, [`r e2_contrasts_ent$hdi_lower[5]`, `r e2_contrasts_ent$hdi_upper[5]`]. There was some (weaker) evidence of greater reduction in entropy in the Learning goal condition ($\beta$ = `r e2_contrasts_ent$ent_change[1]`, [`r e2_contrasts_ent$hdi_lower[1]`, `r e2_contrasts_ent$hdi_upper[1]`). There was no evidence of a main effect of social context and no two- or three-way interactions between social context, goal condition, and type of action choice.

### BDA model-data fit:

```{r bda load}
load(here("model/BDA/e2/results/soc-info-ver1-mcmc100000_burn50000_4chains.RData"))

optimality <- d %>% 
  filter(grepl("optimal", parameter)) %>%
  group_by(parameter) %>%
  summarise(ci_lower = round(hdi_lower(value),2),
            ci_upper = round(hdi_upper(value),2),
            mean = round(mean(value),2))

postpred <- d %>%
  filter(grepl("posterior", parameter)) %>%
  filter(!(goal == "presentation" & obsPres == "0")) %>%
  group_by(goal, context, action) %>%
  summarise(prob = mean(value),
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value)
            )
```

```{r bda cor2}
d_e2 <- fromJSON(here("model/BDA/e2/e2-actionData.json"))

d_e2_pred <- d_e2 %>%
  mutate(context = fct_recode(factor(obsPres),
                              "social" = "1",
                              "no-social" = "0"
                              )) %>%
  mutate(goal = fct_recode(goal, "no goal" = "noGoal")) %>%
  distinct(goal, context, action, id) %>%
  count(action, goal, context) %>%
  group_by(goal, context) %>%
  mutate(data_prob = n / sum(n)) %>%
  mutate(data_ci_lower = binom.bayes(x = n, n = sum(n), conf.level = 0.95) %>% pull(lower),
         data_ci_upper = binom.bayes(x = n, n = sum(n), conf.level = 0.95) %>% pull(upper)) %>%
  select(-n)

data_mod <- left_join(postpred, d_e2_pred)

cor2 = round(with(data_mod, cor(data_prob, prob, use="na.or.complete"))^2,3)
```

In our paradigm, participants were instructed to choose an action\footnote{For action priors, we used a separate prior elicitation task, in which people indicated the likelihood for selecting an action without any background information about possible hypotheses or goals. The results suggested that none of the action choice priors statistically differed from chance. We used mean likelihood for each action choice as baseline priors in our model.} based on a certain goal. 
We assumed that the goal descriptions (e.g. "impress your boss") conveyed to the participants a particular set of goal weights {$\phi_{learn}$, $\phi_{perf}$, $\phi_{pres}$} used to generate action choices. We put uninformative priors on these weights ($\phi \sim Unif(0,1)$) and inferred their credible values separately for each social-goal condition, using Bayesian data analytic techniques [@lee2014bayesian]. 

The inferred goal weights were consistent with what we predicted (see Figure \ref{fig:e2_results}D). $\phi_{learn}$ was at its highest for no-social learning condition, in which the goal to learn was highlighted, and there was minimum social pressure. On the other hand, the $\phi_{perf}$ and $\phi_{pres}$ together make up the highest portion in the presentation condition, with high social pressure to present competence, compared to other conditions.

We also inferred another parameter of the cognitive model, the optimality parameter $\lambda$. We put uninformative prior on the parameter ($\lambda \sim Uniform(0,10)$ and inferred its posterior credible value from the data. We ran 4 MCMC chains for 100,000 iterations, discarding the first 50,000 for burnin. The Maximum A- Posteriori (MAP) estimate and 95% Highest Probability Density Interval (HDI) for $\lambda$ was `r optimality$mean` [`r optimality$ci_lower`, `r optimality$ci_upper`]. 

The predictions of the action choices according to the fitted learner model are shown in Figure \ref{fig:e2_results}A (bottom). The model's expected posteriors over action choices capture key differences between conditions: the single action was more likely for no-social than social conditions overall, but not when the performance goal was highlighted. The model was able to predict the distribution of action responses with high accuracy $r^2(21)$ = `r cor2`.

# General Discussion

How does the social context shape our decisions in an active learning environment? 
We proposed that people's decisions reflect a tradeoff between learning- vs. performance-oriented goals, 
and that the social context affects the goal to present oneself as competent, and may encourage pursuit of immediate reward. 
In two experiments, people's behaviors were in line with our hypothesis, 
as they chose more informative actions when learning goals were highlighted with no boss present, while they chose more immediately rewarding actions when performance or presentational goals were highlighted, especially when the boss was present. 
When no goal was specified, people showed behavior that seemed to reflect a mix of the goals in tradeoff. 
Our model successfully captured key patterns in the behavioral data. 

There remain many interesting questions for future work. 
For example, what is the relationship between the performance and presentational goals? 
In the current work, performance and presentational goals, as well as social context with the presence of another person, all led to action choices in favor of immediate rewards.
Is presentation then just one instantiation of performance goal?
That is, do people always want to exploit their current knowledge 
and present their knowledge or competence to another person?
In our paradigm, we used the presence of a boss to represent a social context 
that influences people’s action choices in an active learning scenario.
But we may see different behaviors in other kinds of social contexts,
depending on the *observer*'s goals
(e.g. a teacher who wants the learner to explore).

Another highly relevant issue is the development of goal understanding:
How does the ability to balance between learning versus self-presentation goals emerge and develop?
One possibility is that young children focus on learning and gathering new information from the world,
but as their social reasoning abilities mature,
children may pay more attention to social circumstances 
and try to balance between their want for exploration versus exploitation.
Our work represents the first step to answering these questions that 
ultimately seek to unify theories on active learning and social reasoning.

# Acknowledgements

This work was supported by NSERC postgraduate doctoral scholarship PGSD3-454094-2014 to EJY and an NSF GRFP to KM [FIXME].

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}

\noindent
