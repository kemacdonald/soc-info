% Template for Cogsci submission with R Markdown

% Stuff changed from original Markdown PLOS Template
\documentclass[10pt, letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{float}
\usepackage{caption}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}

% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% hyperref package, useful for hyperlinks
\usepackage{hyperref}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% Sweave(-like)
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}
\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}
\newenvironment{CodeChunk}{}{}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color}

% Use doublespacing - comment out for single spacing
%\usepackage{setspace}
%\doublespacing


% % Text layout
% \topmargin 0.0cm
% \oddsidemargin 0.5cm
% \evensidemargin 0.5cm
% \textwidth 16cm
% \textheight 21cm

\title{Learning in social context}


\author{{\large \bf Erica J. Yoon}, {\large \bf Kyle MacDonald}, \and {\large \bf Mika Asaba} \\ \{ejyoon, kylem4, masaba\} @stanford.edu \\ Department of Psychology, Stanford University}

\begin{document}

\maketitle

\begin{abstract}
\ldots{}

\textbf{Keywords:}
Learning; social context; information gain; OED; self-presentation; goal
tradeoff
\end{abstract}

\section{Introduction}\label{introduction}

Learning takes place in social contexts.

A simple case study of situations where people have to decide between
information gain and self-presentation,

\section{Computational model}\label{computational-model}

Our model works under the same key assumption as that in recent
computational models of social cognition: that people act approximately
optimally given a utility function. In Yoon, Tessler, Goodman, \& Frank
(2017), the speaker's total utility was represented as a weighted
combination of informational and social utilities, reflecting a
principled tradeoff between the two utilities. Similarly, we propose a
model of a learner who considers different utilities and chooses to
prioritize one over another. We consider three utilities:
\emph{learning}, \emph{performance}, and \emph{presentational}.

First, the \emph{learning utility} is represented by an OED model, which
quantifies the \emph{expected utility} of different information seeking
actions. The set of queries is defined as \(Q_1, Q_2, ..., Q_n = {Q}\).
The expected utility of each query (\(EU(Q)\)) is a function of two
factors: (1) the probability of obtaining a specific answer \(P(a)\)
weighted by (2) the usefulness of that answer for achieving the learning
goal \(U(a)\).

\[EU(Q) = \sum_{a\in q}{P(a)U(a)}\]

There are a variety of ways to define the usefulness function to score
each answer (for a detailed analysis of different approaches, see Nelson
(2005)). One standard method is to use \emph{information gain}, which is
defined as the change in the learner's overall uncertainty (difference
in entoropy) before and after receiving an answer.

\[ U_{learning} = U(a) = ent(H) - ent(H|a)\]

Where \(ent(H)\) is defined using Shannon entropy
\footnote{Shannon entropy is a measure of unpredictability or amount of uncertainty in the learner's probability distribution over hypotheses. Intuitively, higher entropy distributions are more uncertain and harder to predict. For example, if the learner believes that all hypotheses are equally likely, then they are in a state of high uncertainty/entropy. In contrast, if the learner firmly believes in one hypothesis, then uncertainty/entropy is low.}
MacKay (2003), which provides a measure of the overall amount of
uncertainty in the learner's beliefs about the candidate hypotheses.

\[ent(H) = -\sum_{a\in A}{P(h)log_2P(h)}\]

The conditional entropy computation is the same, but takes into account
the change in the learner's beliefs after seeing an answer.

\[ ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)} \]

To calculate the change in the learner's belief in a hypothesis
\(P(h|a)\), we use Bayes rule.

\[ P(h|a) = \frac{P(h)P(a|h)}{P(a)} \]

The learner performs the expected utility computation for each query in
the set of possible queries and picks the one that maximizes utility. In
practice, the learner considers each possible answer, scores the answer
with the usefulness function, and weights the score using the
probability of getting that answer.

Second, the \emph{performance utility} is the utility of successfully
making the toy operate. Specifically within our current paradigm, the
performance utility is the expected utility of music playing (\(m\))
given the learner's action \(a\).

\[ U_{performance} = \ln(P_L(m | a)) \] When there is no observer
present, the learner considers the tradeoff between the learning utility
and performance utility, and he determines his action based on a
weighted combination of the two utilities:

\[ U(a;\phi; obs = no) = \phi \cdot U_{learning} + (1-\phi) \cdot U_{performance} ,\]
\noindent
where \(\phi\) is a mixture parameter governing the extent to which the
learner prioritizes information gain over making the toy play music.

When there is another person present to observe the learner's action,
this observer \(O\) reasons about the competence \(c\) of the learner
\(L\) which is equal to whether the learner was able to make the toy
work.

\[ P_O(c) \propto P_L(m | a)\]

The learner thinks about how the observer infers the learner's
competence, and the \emph{presentational} utility then is based on
maximizing the apparent competence inferred by the observer.

\[ U_{presentation} = \ln(P_O(c)) \] Thus, when there is an observer
present, the learner considers the tradeoff between the learning utility
and presentational utility:

\[ U(m;a;\phi; obs = yes) = \phi \cdot U_{learning} + (1-\phi) \cdot U_{presentational}\]
Based on the utility functions above, the learner (\(L\)) chooses his
action \(a\) approximately optimally (as per optimality parameter
\(\lambda\)) given his goal weight and observer presence.

\[ P_L(a | \phi, obs) \propto \exp(\lambda \cdot \mathbb{E}[U(a;\phi; obs)])\]

\section{Experiment}\label{experiment}

\subsection{Method}\label{method}

\subsubsection{Participants}\label{participants}

FIXME participants with IP addresses in the United States were recruited
on Amazon's Mechanical Turk.

\subsubsection{Stimuli and Design}\label{stimuli-and-design}

We asked participants to imagine they were children's toy developers. We
presented three different toys that look very similar but each work in
different ways, and provided instructions for them. \emph{The
ButtonMusic toy} instructions were: \emph{``Press the button on the
right to play music. Pull the handle on the left to turn on the light.
Doing both produces both effects.''} ``\emph{The HandleMusic toy}
instuctions were: \emph{``Pull the handle on the left to play music.
Press the button on the right to turn on the light. Doing both produces
both effects.''} and''\emph{the BothMusicLight toy} instuctions were:
\emph{``Pull the handle on the left AND press the button on the right to
turn on the light and play music at the same time. The button press or
handle pull on its own doesn't produce any effect.''} Each toy had a
label showing its name.

We presented a story to the participants that their boss motivated a
goal the participants must achieve by acting on the toy. Importantly,
the toy was missing its label, such that partcipants could not know
whether the toy was a ButtonMusic, HandleMusic, or BothMusicLight toy.
In the \emph{learning} condition, the boss said ``That must be one of
the new toys that you've been working on. But it looks like you forgot
to put on the label! Can you figure out whether this toy is a
ButtonMusic toy, HandleMusic toy, or BothMusicLight toy?''; in the
\emph{performance} condition, the boss said ``That must be one of the
new toys that you've been working on. I want to hear the music it
plays.''; and in the \emph{presentation} condition, the boss said ``That
must be one of the new toys that you've been working on. How does it
work?'' followed by the prompt ``\ldots{} you only had one chance to
impress your boss and show that you're competent \ldots{}'' Then we
asked participants to select one action to try out on the toy: to
``press the button'', ``pull the handle'', or ``press the button and
pull the handle.'' Each participant was randomly assigned to one of
three goal conditions, and shown a randomized order of actions to choose
from.

\subsubsection{Procedure}\label{procedure}

Participants were first introduced to the task and shown a picture of a
toy with labels on its parts. Then they read instructions for each of
the three toys, after which they were asked what they would do to make
the toy play music and to make it turn on the light, to make sure they
understood the instructions. We then asked participants to rate prior
likelihood that an unknown toy is a ButtonMusic toy, HandleMusic toy, or
BothMusicLight toy. Participants read a scenario for one of the three
goal conditions, and the following instruction: ``If you only had one
chance to try a SINGLE action to {[}goal{]}, which action would you want
to take? You will get a 10 cent bonus after submitting the HIT if you
{[}goal{]}.'' After selecting a response out of three possible actions,
the participants were asked again to rate the likelihood for which toy
the unlabeled toy was. The experiment can be viewed at
\url{https://langcog.stanford.edu/expts/EJY/soc-info/goal_actions_ver2/soc_info_goals.html}.

\section{Results}\label{results}

\section{Discussion}\label{discussion}

\section{Acknowledgements}\label{acknowledgements}

This work was supported by NSERC postgraduate doctoral scholarship
PGSD3-454094-2014 to EJY \ldots{} FIXME.

\section{References}\label{references}

\setlength{\parindent}{-0.1in} \setlength{\leftskip}{0.125in} \noindent

\hypertarget{refs}{}
\hypertarget{ref-mackay2003}{}
MacKay, D. J. (2003). \emph{Information theory, inference and learning
algorithms}. Cambridge university press.

\hypertarget{ref-nelson2005}{}
Nelson, J. D. (2005). Finding useful questions: On bayesian
diagnosticity, probability, impact, and information gain.
\emph{Psychological Review}, \emph{112}(4).

\hypertarget{ref-yoon2017}{}
Yoon, E. J., Tessler, M. H., Goodman, N. D., \& Frank, M. C. (2017). ``I
won't lie, it wasn't amazing'': Modeling polite indirect speech. In
\emph{Proceedings of the thirty-ninth annual conference of the Cognitive
Science Society}.

\end{document}
