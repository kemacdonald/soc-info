% Template for Cogsci submission with R Markdown

% Stuff changed from original Markdown PLOS Template
\documentclass[10pt, letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{float}
\usepackage{caption}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}

% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% hyperref package, useful for hyperlinks
\usepackage{hyperref}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% Sweave(-like)
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}
\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}
\newenvironment{CodeChunk}{}{}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color}

% Use doublespacing - comment out for single spacing
%\usepackage{setspace}
%\doublespacing


% % Text layout
% \topmargin 0.0cm
% \oddsidemargin 0.5cm
% \evensidemargin 0.5cm
% \textwidth 16cm
% \textheight 21cm

\title{Should I learn or should I make it go? ~Balancing informational and
social goals in active learning}


\author{{\large \bf Erica J. Yoon*}, {\large \bf Kyle MacDonald*}, {\large \bf Mika Asaba}, {\large \bf Hyowon Gweon}, \and {\large \bf Michael C. Frank} \\ \{ejyoon, kylem4, masaba, hyo, mcfrank\} @stanford.edu \\ Department of Psychology, Stanford University \\ *These authors contributed equally to this work.}

\begin{document}

\maketitle

\begin{abstract}
Our actions shape what we learn. Recent work suggests that people engage
in efficient self-directed learning to maximize information gain.
However, human learning often unfolds in social contexts where learners
not only face informational goals (e.g.~learn how something works) but
also social goals (e.g.~appear competent and impress others). How do
these factors shape learners' decisions? Here, we present a
computational model that integrates the value of social and information
goals to predict the decisions that people will make in a simple active
causal learning task. We show that an emphasis on performance or
self-presentation goals leads to reduced chances of learning (E1). Next,
we show that social context can push learners to pursue
performance-oriented actions even when the learning goal is highlighted
(E2). Our formal model of social-active learning successfully captures
the empirical results. These findings are the first steps towards
understanding the role of social reasoning in active learning contexts.

\textbf{Keywords:}
active learning; social reasoning; information gain; OED;
self-presentation; goal tradeoffs
\end{abstract}

\section{Introduction}\label{introduction}

Imagine you are a novice cook and you have to decide what meal to
prepare for a first date. Should you choose an easy favorite or should
you attempt to make something new? While the familiar recipe can ensure
a good meal, you may miss out on a new, delicious dish. The new recipe
might taste even better, but it has a higher chance of failure.

We often have to choose between \emph{exploration} and
\emph{exploitation}: that is, actions that could (a) lead to an overt,
readily accessible reward based on what we already know
(\emph{exploitation}) or (b) result in the discovery of new information
(\emph{exploration}; Sutton \& Barto, 1998). This decision of whether to
explore or exploit is directly related to the relative strength of the
goals within a particular context. In the cooking example, I can
prioritize the goal of learning by cooking the new recipe, or I can
instead focus on the performance goal by preparing the tried and true
meal. Here, we explore the idea of this learning-performance goal
tradeoff in a simple active learning context, where social factors may
affect the goals we consider.

\emph{Active learning} refers to situations where people are given
control over the sequence of information in a learning context (e.g.~try
pressing different buttons on a toy, one by one, to see whether it
produces an effect). The key assumption is that learners will maximize
the usefulness of their actions by gathering information that is
especially helpful for their own learning. The effects of active
learning have been the focus of much empirical work in education
(Grabinger \& Dunlap, 1995), machine learning (Settles, 2012), and
cognitive psychology (Castro et al., 2009), with the common finding that
active contexts lead to faster learning than passive contexts where
people don't have control over the information flow.

But real-world learning usually takes place in richly social contexts
with teachers, peer learners, or other individuals who can directly
influence our learning. Indeed, it has been suggested that children and
adults modulate their inferences depending on whether they generate
their own evidence, or learn from evidence generated by others (e.g. Xu
\& Tenenbaum, 2007). Work on pedagogical reasoning show that children
learn faster when observing intentional (more informative) actions
compared to accidental (less informative) actions. Moreover, adults and
children will make even stronger inferences if they believe that another
person selected their actions with the goal of helping them learn (i.e.,
teaching) (Shafto, Goodman, \& Frank, 2012).

However, social influences are not only present when we learn from
others. Even when we learn from our own actions, that learning often
unfolds in social contexts, which may affect our self-directed learning
process. While previous models have captured how we optimize learning,
either from our own actions or from others, they have been agnostic to
other social factors that are ubiquitous in a learner's environment.
People must integrate the value of social goals -- looking competent or
knowledgeable, for example -- and information goals when deciding what
to do next. Moreover, actions that maximize learning are inherently
risky in that you can potentially fail to produce an apparent outcome,
and thus may be more difficult to undertake in with someone else present
who might judge you as incompetent.

How can active learning models be modified to accommodate this richer
set of utilities? As a step towards answering this question, we model a
learner who considers a mixture of learning and performance goals. A key
assumption underlying inferences in recent Bayesian models of human
social cognition is that people expect others to act approximately
optimally given a utility function (e.g. Goodman \& Frank, 2016;
Jara-Ettinger, Gweon, Schulz, \& Tenenbaum, 2016). Our model adopts the
same utility-theoretic approach, and assumes an approximately optimal
agent who reasons about the utility function that represents a weighted
combination of multiple goals (Yoon, Tessler, Goodman, \& Frank, 2017).
Our model thus reflects a tradeoff between different goals that a
learner has in a social learning context.

We instantiate our model in a simple causal learning task and examine
whether people choose actions that support learning vs.~social goals. We
present a toy with an uncertain causal mechanism (Figure \ref{fig:toy}),
for which doing only one of the two possible actions (handle pull or
button press) is disambiguating but potentially risks no immediate
effect (i.e.~neither sound nor light turning on), while doing both
actions simultaneously is immediately rewarding for sure but is not
informative for learning the toy's causal mechanism. Thus, the learner
can choose between the two actions that will each lead to one outcome
(new discovery) or the other (immediate reward). The learner's action
rests on relative utilities he assigns to exploration versus
exploitation, which in turn are determined in part by the presence or
absence of another person he cares about (i.e.~his
boss).\footnote{From here on, we use a male pronoun for Bob, the learner, and female pronoun for Ann, the boss and observer.}

In two experiments, we show that emphasizing performance or
self-presentation goals leads to actions that are not informative and
thus reduce the chances of learning (E1). Next, we show that the
presence of an observer (i.e., a boss) pushes learners to pursue
performance/presentation actions even when the learning goal is
highlighted (E2). Finally, we present a Bayesian Data Analysis showing
that the empirical results are consistent with predictions of our
cognitive model of social-active learning.

\section{Computational model}\label{computational-model}

\begin{CodeChunk}
\begin{figure}[t]

{\centering \includegraphics[width=0.8\linewidth]{figs/toy-1} 

}

\caption[An example of the toy used in our paradigm]{An example of the toy used in our paradigm.}\label{fig:toy}
\end{figure}
\end{CodeChunk}

\begin{CodeChunk}
\begin{figure*}[tb]

{\centering \includegraphics[width=0.95\linewidth]{figs/model_diagram-1} 

}

\caption[Diagram of the computational model]{Diagram of the computational model. The learner considers possible hypotheses: Toy 1 (handle pull turns on the light, button press turns on music, both actions cause both effects); Toy 2 (handle pull turns on music, button press turns on the light, both actions cause both effects); and Toy 3 (both actions cause both effects, but each action on its own does not produce any effect). The learner also considers his contextual goals. When an observer is absent, he considers his learning goal (to maximize information gain) and performance goal (e.g. to play music) and decides on an action. The learning goal favors a single action (e.g. pull the handle only) that can fully disambiguate, whereas the performance goal favors the both action (pull the handle AND push the button) that guarantees the most salient reward. When an observer is present, his decision for an action is based on his learning goal vs. presentational goal (to have the observer infer his competence or knowledge of how the toy works).}\label{fig:model_diagram}
\end{figure*}
\end{CodeChunk}

We model a learner's action choice based on his desire to learn how a
toy works (\emph{learning utility}), to make the toy operate and perform
a given function (\emph{performance utility}), or to present himself as
a competent individual who knows how to make the toy work
(\emph{presentational utility}; see the model diagram in Figure
\ref{fig:model_diagram}).

\subsubsection{Learning utility}\label{learning-utility}

The \emph{learning utility} symbolizes the goal to learn new
information, which in our paradigm is associated with figuring out how a
given toy works. The learning utility is formally represented by an OED
model (Lindley, 1956; ``Optimal Experiment Design''; Nelson, 2005),
which quantifies the \emph{expected utility} of different information
seeking actions. Here we follow the mathematical details of the OED
approach as outlined in Coenen, Nelson, \& Gureckis (2017). The learner
considers the hypothesis space \(H\), and wants to determine the correct
hypothesis. Based on a set of queries, each realized through taking an
action, the learner thinks about the utility of the answer to each
query. The utility of answer is equal to the \emph{information gain},
which is the change in the learner's overall uncertainty (difference in
entropy) before and after receiving an answer. This information gain is
then the usefulness of the answer to the query, and thus is equal to the
learning utility (\(U_{learn}\)):

\[ U_{learn} = U(a) = \frac{ent(H) - ent(H|a)}{log_2n}\] \noindent
where \(ent(H)\) is the Shannon entropy of \(H\), which provides a
measure of the overall amount of uncertainty in the learner's beliefs
about the candidate hypothesis(MacKay, 2003). Once the learner chooses a
query \(Q\), which yields an answer \(a\), then he updates his beliefs
about each hypothesis via standard Bayesian updating. Finally, the
difference in entropy is normalized by \(log_2 n\), where \(n\) is the
number of possible actions, to generate a value between 0 and 1.

\subsubsection{Performance utility}\label{performance-utility}

The \emph{performance utility} is the utility of successfully making the
toy operate and achieving an immediate rewarding outcome. Within our
current paradigm, the learner gains utility by seeing an immediate
effect of music or light turning on. The expected performance utility
(\(U_{perf}\)) before the learner chooses an action is then the
likelihood of an effect (\(m\)) given the learner's action \(a\).

\[ U_{perf} = P_L(m | a) \] \noindent
Thus, performance utility is maximized by taking an action that is most
likely to make the toy ``go'' and play music or turn the light on.

When there is no observer present (\(obs = no\)), the learner considers
the tradeoff between the learning utility and performance utility, and
he determines his action based on a weighted combination of the two
utilities:

\[ U(\phi; obs = no) = \phi_{learn} \cdot U_{learn} + \phi_{perf} \cdot U_{perf} ,\]
\noindent
where \(\phi\) is a mixture parameter governing the extent to which the
learner prioritizes learning over performance.

\subsubsection{Presentation utility}\label{presentation-utility}

When there is another person present to observe the learner's action,
this observer \(O\) is expected to reason about the competence \(c\) of
the learner \(L\) which is equal to whether the learner was able to make
the toy produce an effect. The learner thinks the observer's inferential
process, and the expected \emph{presentational} utility (\(U_{pres}\))
is based on maximizing the apparent competence inferred by the observer.

\[ P_O(c) \propto P_L(m | a)\] \[ U_{pres} = P_O(c)\] When there is an
observer present (\(obs = yes\)), the learner considers the tradeoff
between all three utilities: the learning utility, performance utility
and presentational utility:

\[ U(\phi; obs = yes) = \phi_{learn} \cdot U_{learn} + \\ \phi_{perf} \cdot U_{perf} + \phi_{pres} \cdot U_{pres}\]
Based on the utility functions above, the learner (\(L\)) chooses his
action \(a\) approximately optimally (as per optimality parameter
\(\lambda\)) based on the expected utility given his goal weight and
observer presence.

\[ P_L(a | \phi, obs) \propto \exp(\lambda \cdot \mathbb{E}[U(\phi; obs)])\]

\section{Experiment 1}\label{experiment-1}

In Experiment 1, we first wanted to confirm that participants would
choose different actions depending on what goal was highlighted. We were
also interested in how people would act when no goal was specified.
Importantly, participants were limited to selecting a \emph{single}
action, which meant the opportunity cost was at its highest.
Participants were asked to imagine that they needed to act on a toy with
an uncertain causal mechanism, and were assigned to different goal
conditions: (1) learning (learn how the toy works), (2) performance
(make the toy play music), (3) presentation (impress their boss), and
(4) no goal specified. We hypothesized that participants would choose an
informative action more often in the following order of goal conditions
(decreasing): learning, no goal, performance, and
presentation.\footnote{Our hypothesis, method, model and data analysis were pre-registered prior to data collection on the Open Science Framework (https://osf.io/kcjau). All experiments, data, model scripts, and analysis codes for the statistical models can be found in the online repository for this project: https://github.com/kemacdonald/soc-info.}

\begin{CodeChunk}
\begin{figure*}[tb]

{\centering \includegraphics[width=0.95\linewidth]{figs/e1_behav_results_plot-1} 

}

\caption[Behavioral results for E1]{Behavioral results for E1. Panel A shows the proportion of action decisions for each goal condition. Error bars represent 95\% binomial confidence intervals computed using a Bayesian beta-binomial model. Panel B shows violin plots of participants' response times on the action decisions. Each point represents a participant with the width of the violin representing the density of the data at that value. Panel C shows violin plots of participants' belief change (entropy) as a function of condition. Lower values represent higher certainty after selecting an action. Color in panels A and C represent the type of action participants selected.}\label{fig:e1_behav_results_plot}
\end{figure*}
\end{CodeChunk}

\subsection{Method}\label{method}

\subsubsection{Participants}\label{participants}

We recruited 196 participants (FIXME - FIXME for each condition) on
Amazon's Mechanical Turk, with IP addresses in the United States and a
task approval rate above 85\%. We excluded 7 participants who failed to
answer at least two out of three manipulation check questions correctly
(see Procedure section for details on the manipulation check), and thus
the remaining 189 participants were included in our final analysis.

\subsubsection{Stimuli and Design}\label{stimuli-and-design}

We presented images of three different toys that look very similar but
each work in different ways, and provided instructions for them (see
captions for Figure \ref{fig:model_diagram}). Based on the instructions,
doing both button press and handle pull was immediately rewarding but
uninformative (as it does not disambiguate the causal mechanism in any
way), whereas either of the single actions was completely
disambiguating, but was uncertain to produce an immediate outcome. Each
toy had a label at the front, indicating which action(s) will make the
toy operate, and with which outcome effect.

We asked participants to act on one of these toys; importantly, the
given toy was missing its label, such that partcipants could not know
whether the toy was Toy 1, 2 or 3. We assigned participants into four
goal conditions. In \emph{no-goal} condition, participants were asked to
select an action without any goal specified. In \emph{learning},
\emph{performance}, and \emph{presentation} conditions, we asked
participants to imagine that they were children's toy developers and
that one day their boss approached them. We then instructed participants
to: figure out the correct label for the toy (\emph{learning}
condition); make the toy play music (or turn the light on;
\emph{performance} condition); or impress their boss and show that they
are competent (\emph{presentation} condition). We asked participants to
select an action they would like to try out on the toy in order to
accomplish the specified goal (if any), out of three possible actions:
to ``press the button'', ``pull the handle'', or ``press the button and
pull the handle.'' We randomly assigned each participant to one of the
four goal conditions, and randomized the order of actions to choose
from.

\subsubsection{Procedure}\label{procedure}

In the initial \emph{exposure phase}, we first showed participants a
picture of a possible toy with labels on its different parts (Figure
\ref{fig:toy}). Then they read instructions for each of the three toy
types. We presented Toy 1 and Toy 2 instructions in a randomized order
first, and then Toy 3 instructions. Afterwards, they were asked what
they would do to make the toy operate as manipulation check (e.g. ``How
would you make the toy play music?'').

In the \emph{test phase}, participants read a scenario for one of the
three goal conditions, followed by the question: ``If you only had one
chance to try a SINGLE action to {[}pursue the specified goal{]}, which
action would you want to take? You will get a 10 cent bonus \ldots{} if
you {[}achieve the given goal{]}''. Participants made their \emph{action
decisions} accordingly. Before and after they chose an action and saw
its effect on the toy, we asked participants to rate the likelihood that
an unknown toy is Toy 1, 2, or 3, which indicated their \emph{belief
change} between before and after their decisions.

\subsection{Results and discussion}\label{results-and-discussion}

\subsubsection{Analysis plan}\label{analysis-plan}

We present behavioral analyses of participants' (1) action decisions,
(2) action decision times, and (3) belief change (i.e., learning).
Decision times correspond to the latency to make an action selection as
measured from the start of the action decision trial (all RTs were
analyzed in log space). We quantified participants' beliefs about the
possible toy designs using entropy, and belief change was measured as
the difference in entropy before and after selecting an action.

We used the \texttt{rstanarm} (Gabry \& Goodrich, 2016) package to fit
Bayesian regression models estimating the differences across conditions.
We report the uncertainty in our point estimates using 95\% Highest
Density Intervals (HDI). The HDI provides a range of credible values
given the data and model.

\subsubsection{Action decisions:}\label{action-decisions}

We modeled action decisions using a logistic regression specified as
\texttt{$action \sim goal\_condition$} with the No-Goal condition as the
reference category. Participants' tendency to select a ``single'' action
varied across conditions in the predicted pattern (see Panel A of Figure
\ref{fig:e1_behav_results_plot}), with the highest proportion occuring
in the Learning context, followed by the No Goal context, then
Performance, and the fewest single actions in the Presentation
condition.

Compared to the No-Goal condition, participants selected the single
action at a greater rate in the Learning condition (\(\beta\) = 1.28,
{[}0.5, 2.17{]}) and at lower rate in the Presentation context
(\(\beta\) = -1.41, {[}-2.47, -0.4{]}), with the null value of zero
difference condition falling well outside the 95\% HDI, and at similar
rate in the Performance condition (\(\beta\) = -0.53, {[}-1.43, 0.35{]})
with the 95\% HDI including the null.

\subsubsection{Action decision times:}\label{action-decision-times}

We analyzed response times in log space using the same model
specification. Panel A of Figure \ref{fig:e1_behav_results_plot} shows
the full RT data distribution. Compared to the No-Goal condition,
participants took on on average 12.2 seconds longer to generate a
decision in the Learning condition, but produced similar response times
in the Performance and Presentation conditions.

\subsubsection{Belief change:}\label{belief-change}

We modeled change in entropy as a function of goal condition and
participants' action selections:
\texttt{$entropy\_change \sim goal\_condition + action\_response$} (see
Panel C of Figure \ref{fig:e1_behav_results_plot}) . Across all
conditions, people who selected the single action showed a greater
reduction in entropy (\(\beta\) = -0.49, {[}-0.64, -0.33{]}, i.e.,
learned more from their action. We did not see evidence of an
interaction between goal condition and action selection. However, recall
that a larger proportion of participants selected the single action in
the Learning context, so the probability of learning is higher in this
scenario.

\begin{CodeChunk}
\begin{figure*}[tb]

{\centering \includegraphics[width=0.95\linewidth]{figs/e2_results-1} 

}

\caption[Behavioral and model fitting results for E2]{Behavioral and model fitting results for E2. Panel A shows actions decisions with color representing social context, from human data (top) and fitted model predictions (bottom). Panel B shows decision times. Panel C shows belief change. Panel D shows inferred phi values for each goal-context condition. All other plotting conventions are the same as Figure 3.}\label{fig:e2_results}
\end{figure*}
\end{CodeChunk}

\section{Experiment 2}\label{experiment-2}

In Experiment 1, we confirmed that participants made different action
choices depending on the goal conditions, as we previously predicted. In
Experiment 2, our goals were three-fold: (1) to replicate the results in
E1 to see whether people choose the same action choices given the same
goal conditions; (2) to manipulate goals \emph{and} social contexts,
fully crossing the different goal conditions with the presence/absence
of the boss, to see whether the social context affects people's decision
differently in each goal condition; and (3) to compare the empirical
data with the predictions of the model. We hypothesized that
participants in the no-social learning/no-goal condition will select the
single action option at a greater rate compared to the social
learning/no-goal condition, but they should select the both action
option at the same, high rate in the social and no-social performance
condition.

\subsection{Method}\label{method-1}

\subsubsection{Participants}\label{participants-1}

We recruited 347 participants (\textasciitilde{}50 for each condition)
on Amazon's Mechanical Turk. We used same exclusion criteria as E1; we
excluded 22 participants and thus the remaining 325 participants were
included in our final analysis.

\subsubsection{Stimuli and Design}\label{stimuli-and-design-1}

The stimuli and design were identical to Experiment 1, except we had
seven different goal \(\times\) social conditions. Goals remained
identical to ones presented in Experiment 1; social conditions varied
depending on whether the boss was present in the story (\emph{social})
or she was absent (\emph{no-social}). Thus, the conditions from
Experiment 1 were used as \emph{social-learning},
\emph{social-performance}, \emph{social-presentation}, and
\emph{no-social-no-goal} conditions in Experiment 2. We added three more
conditions: \emph{no-social-learning}, \emph{no-social-performance}, and
\emph{social-no-goal}. Note that we did not have
\emph{no-social-presentation} condition, because presentation goal by
definition was to present oneself as competent to and impress another
person.

\subsubsection{Procedure}\label{procedure-1}

The procedure was identical to Experiment 1.

\subsection{Results and discussion}\label{results-and-discussion-1}

\subsubsection{Action decisions:}\label{action-decisions-1}

We modeled action decisions using a logistic regression specified as
\texttt{$action \sim goal\_condition * social\_context$} with the
No-Goal and No-Social condition as the reference category. We replicated
the key finding from E1: participants tended to select the ``single''
action more often when they were within a context that emphasized a
learning goal, followed by the No Goal context, then Performance, with
the fewest single actions generated in the Presentation condtion.

There was a main efffect of social context, with participants being less
likely to select the single action when their boss was present
(\(\beta =\) -0.521, {[}-1.005, -0.053{]}). Finally, there was evidence
for a reliable interaction between goal condition and social context
such that the effect of social context was present in the Learning and
No-Goal conditions, but not in the Performance condition (\(\beta\)
\(_{int}\) = 1.163, {[}0.01, 2.312{]}).

\subsubsection{Action decision times:}\label{action-decision-times-1}

We replicated the key decision time finding from E1: slower decision
times in the Learning context. On average, participants took seconds to
generate a response in the No-goal condidition and seconds in the
Learning condition. In contrast, decisions were faster in the
Performance (\(\beta\) = -7.78 sec, {[}-14.01, -1.52{]}) and
Presentation (-10.77 seconds, {[}-18.67, -2.73{]}) conditions, which
were similar to one another (see Panel B of Fig \ref{fig:e2_results}).
There was no evidence of a main effect of social context or an
interaction between goal condition and social context. Note that we did
not see a difference in decision times between the Learning and No-Goal
conditions, which is different from the pattern in E1.

\subsubsection{Belief change:}\label{belief-change-1}

Across all conditions, participants who selected the single action
showed a greater reduction in entropy (\(\beta\) = -0.35, {[}-0.45,
-0.24{]}. There was some (weaker) evidence of greater reduction in
entropy in the Learning goal condition (\(\beta\) = -0.12, {[}-0.25,
0.01). There was no evidence of a main effect of social context and no
two- or three-way interactions between social context, goal condition,
and type of action choice.

\subsubsection{BDA model-data fit:}\label{bda-model-data-fit}

In this experiment, participants were instructed to choose an
action\footnote{For action priors, we used a separate prior elicitation task, in which people indicated the likelihood for selecting an action without any background information about possible hypotheses or goals. The results suggested that none of the action choice priors statistically differed from chance. We used mean likelihood for each action choice as baseline priors in our model}
based on a certain goal. We assumed that the goal descriptions (e.g.
``figure out the correct label for the toy'') conveyed to the
participants a particular set of goal weights \{\(\phi_{learn}\),
\(\phi_{perf}\), \(\phi_{pres}\)\} that they used to generate their
action choices. We put uninformative priors on these weights
(\(\phi \sim Uniform(0,1)\)) and inferred their credible values
separately for each pair of different goal condition and social context,
using Bayesian data analytic techniques (Lee \& Wagenmakers, 2014).

The inferred goal weights were consistent with what we predicted (see
Figure \ref{fig:e2_results}, panel D). \(\phi_{learn}\) was at its
highest for no-social learning condition, in which the goal to learn was
highlighted, and there was minimum social pressure. On the other hand,
the \(\phi_{perf}\) and \(\phi_{pres}\) together make up the highest
portion in the presentation condition, with high social pressure to
present competence, compared to other conditions.

We also inferred another parameter of the cognitive model, the
optimality parameter \(\lambda\). We put uninformative prior on the
parameter (\(\lambda \sim Uniform(0,10)\) and inferred its posterior
credible value from the data. We ran 4 MCMC chains for 100,000
iterations, discarding the first 50,000 for burnin. The Maximum A-
Posteriori (MAP) estimate and 95\% Highest Probability Density Interval
(HDI) for \(\lambda\) was 4.79 {[}3.96, 6.2{]}.

The predictions of the action choices according to the fitted learner
model are shown in Figure \ref{fig:e2_results}, panel A (bottom). The
model's expected posteriors over action choices capture key differences
between conditions: the single action was more likely for no-social than
social conditions overall, but not when the performance goal was
highlighted. The model was able to predict the distribution of action
responses with high accuracy \(r^2(21)\) = 0.9.

\section{General Discussion}\label{general-discussion}

How does the social context shape our decision making in an active
learning environment? We proposed that people make decisions based on a
tradeoff between learning- and performance-oriented goals, and that the
social context influences the desire to present oneself as competent and
knowledgeable, and may encourage pursuit of immediate effect outcome. In
two experiments, we confirmed that people's behaviors were in line with
our hypothesis, as they chose more informative actions when learning
goals were highlighted with no boss present, while they chose more
immediately rewarding actions when performance or presentational goals
were highlighted, especially when the boss was present on scene. When no
goal was specified, people showed behavior that seemed to reflect a mix
of the goals in tradeoff. Our computational model successfully captured
key patterns in these behavioral data.

There remain many interesting questions for future work. For example,
what is the relationship between the performance and presentational
goals? In the current work, performance and presentational goals, as
well as social context with the presence of another person, all led to
action choices in favor of immediate rewards. Is presentation then just
one instantiation of performance goal? That is, do people always want to
exploit their current knowledge and present their knowledge or
competence to another person? In our paradigm, we specifically used the
presence of a boss to represent a social context that can influence
people's action choices in an active learning context. But we may see
different behaviors in other kinds of social contexts, depending on
\emph{observer}'s goals toward the learner (e.g.~a teacher who wants the
learner to explore).

Another highly relevant question is about the development of goal
tradeoff understanding: How does the ability to balance between learning
versus self-presentation goals emerge and develop? One possibility is
that young children focus on learning and gathering new information from
the world, but as their social reasoning abilities mature, children may
pay more attention to social circumstances and try to balance between
their want for exploration versus exploitation. Our work represents the
first step to answering these questions that ultimately seek to unify
theories on active learning and social reasoning.

\section{Acknowledgements}\label{acknowledgements}

This work was supported by NSERC postgraduate doctoral scholarship
PGSD3-454094-2014 to EJY and an NSF GRFP to KM {[}FIXME{]}.

\section{References}\label{references}

\setlength{\parindent}{-0.1in} \setlength{\leftskip}{0.125in} \noindent

\hypertarget{refs}{}
\hypertarget{ref-castro2009human}{}
Castro, R. M., Kalish, C., Nowak, R., Qian, R., Rogers, T., \& Zhu, X.
(2009). Human active learning. In \emph{Advances in neural information
processing systems} (pp. 241--248).

\hypertarget{ref-coenen2017}{}
Coenen, A., Nelson, J. D., \& Gureckis, T. M. (2017). Asking the right
questions about human inquiry.

\hypertarget{ref-gabry2016rstanarm}{}
Gabry, J., \& Goodrich, B. (2016). Rstanarm: Bayesian applied regression
modeling via stan. r package version 2.10. 0.

\hypertarget{ref-goodman2016}{}
Goodman, N. D., \& Frank, M. C. (2016). Pragmatic language
interpretation as probabilistic inference. \emph{Trends in Cognitive
Sciences}, \emph{20}(11), 818--829.

\hypertarget{ref-grabinger1995rich}{}
Grabinger, R. S., \& Dunlap, J. C. (1995). Rich environments for active
learning: A definition. \emph{ALT-J}, \emph{3}(2), 5--34.

\hypertarget{ref-jara2016}{}
Jara-Ettinger, J., Gweon, H., Schulz, L. E., \& Tenenbaum, J. B. (2016).
The naïve utility calculus: Computational principles underlying
commonsense psychology. \emph{Trends in Cognitive Sciences},
\emph{20}(8), 589--604.

\hypertarget{ref-lee2014bayesian}{}
Lee, M. D., \& Wagenmakers, E.-J. (2014). \emph{Bayesian cognitive
modeling: A practical course}. Cambridge university press.

\hypertarget{ref-lindley1956}{}
Lindley, D. V. (1956). On a measure of the information provided by an
experiment. \emph{The Annals of Mathematical Statistics}, 986--1005.

\hypertarget{ref-mackay2003}{}
MacKay, D. J. (2003). \emph{Information theory, inference and learning
algorithms}. Cambridge university press.

\hypertarget{ref-nelson2005}{}
Nelson, J. D. (2005). Finding useful questions: On bayesian
diagnosticity, probability, impact, and information gain.
\emph{Psychological Review}, \emph{112}(4).

\hypertarget{ref-settles2012active}{}
Settles, B. (2012). Active learning. \emph{Synthesis Lectures on
Artificial Intelligence and Machine Learning}, \emph{6}(1), 1--114.

\hypertarget{ref-shafto2012learning}{}
Shafto, P., Goodman, N. D., \& Frank, M. C. (2012). Learning from
others: The consequences of psychological reasoning for human learning.
\emph{Perspectives on Psychological Science}, \emph{7}(4), 341--351.

\hypertarget{ref-sutton1998}{}
Sutton, R. S., \& Barto, A. G. (1998). \emph{Introduction to
reinforcement learning} (Vol. 135). MIT Press Cambridge.

\hypertarget{ref-xu2007}{}
Xu, F., \& Tenenbaum, J. B. (2007). Word learning as bayesian inference.
\emph{Psychological Review}, \emph{114}(2), 245.

\hypertarget{ref-yoon2017}{}
Yoon, E. J., Tessler, M. H., Goodman, N. D., \& Frank, M. C. (2017). ``I
won't lie, it wasn't amazing'': Modeling polite indirect speech. In
\emph{Proceedings of the thirty-ninth annual conference of the Cognitive
Science Society}.

\end{document}
