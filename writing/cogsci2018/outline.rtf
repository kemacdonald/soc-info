{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Theories on children\'92s and adults\'92 language social cognition, especially the recent proposals of computational models that try to capture human patterns of reasoning, argue that people expect themselves and others to maximize utilities.\
- jara-ettinger et al 2015\
- RSA models\
\
\
\
\'97\
\
RSA models a listener as reasoning about a speaker who is assumed to choose her utterances approximately optimally given a utility function. \
\
Yoon et al. (2017) defined the speaker\'92s total utility as a weighted combination of informational and social utilities, reflecting a principled tradeoff between the two utilities. \
\
In our model, the learner \
\
\
\
\
\
\
- agent: utility maximizer.\
	utility = weighted combination of multiple utilities\
	here, there are three utilities considered: learning, performance, and presentational\
- learning utility: OED model\
	quantifies the expected value of a question or query in terms of its information gain\
 	where information gain is \
- performance utility: probability that toy will play music\
- presentational utility: equivalent to performance utility, but that probability gets interpreted in the observer\'92s mind as the learner\'92s \'93competence\'94\
	applies when there is another person (\'93observer\'94) present\
\
\
\
\
\
\
$$EU(Q) = \\sum_\{a\\in q\}\{P(a)U(a)\}$$\
\\noindent\
\
There are a variety of ways to define the usefulness function to score each answer (for a detailed analysis of different approaches, see @nelson2005). One standard method is to use *information gain*, which is defined as the change in the learner's overall uncertainty (difference in entoropy) before and after receiving an answer.\
\
$$U(a) = ent(H) - ent(H|a)$$\
\\noindent\
\
Where $ent(H)$ is defined using Shannon entropy ^[Shannon entropy is a measure of unpredictability or amount of uncertainty in the learner's probability distribution over hypotheses. Intuitively, higher entropy distributions are more uncertain and harder to predict. For example, if the learner believes that all hypotheses are equally likely, then they are in a state of high uncertainty/entropy. In contrast, if the learner firmly believes in one hypothesis, then uncertainty/entropy is low.] [@mackay2003], which provides a measure of the overall amount of uncertainty in the learner's beliefs about the candidate hypotheses. \
\
$$ent(H) = -\\sum_\{a\\in A\}\{P(h)log_2P(h)\}$$\
\\noindent\
The conditional entropy computation is the same, but takes into account the change in the learner's beliefs after seeing an answer.\
\
$$ ent(H|a) = -\\sum_\{h\\in H\}\{P(h|a)logP(h|a)\} $$\
\\noindent\
To calculate the change in the learner's belief in a hypothesis $P(h|a)$, we use Bayes rule. \
\
$$ P(h|a) = \\frac\{P(h)P(a|h)\}\{P(a)\} $$ \
\
\\noindent\
The learner performs the expected utility computation for each query in the set of possible queries and picks the one that maximizes utility. In practice, the learner considers each possible answer, scores the answer with the usefulness function, and weights the score using the probability of getting that answer. \
\
- performance utility: probability that toy will play music\
- presentational utility: equivalent to performance utility, but that probability gets interpreted in the observer\'92s mind as the learner\'92s \'93competence\'94\
	applies when there is another person (\'93observer\'94) present\
\
}